<!DOCTYPE html>
<html class="no-js" lang="en">

<head>
    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <title>Mohsen Fayyaz</title>
	<link rel="shortcut icon" href="favicon.ico" type="image/x-icon">
	<link rel="icon" href="favicon.ico" type="image/x-icon">
    <link href="https://fonts.googleapis.com/css?family=Lato:300,400,700,900" rel="stylesheet">
    <link rel="stylesheet" href="libs/font-awesome/css/font-awesome.min.css">
    <link href="css/bootstrap.min.css" rel="stylesheet">
    <link href="css/styles.css" rel="stylesheet">
</head>

<body>
    <div id="mobile-menu-open" class="shadow-large">
        <i class="fa fa-bars" aria-hidden="true"></i>
    </div>
    <!-- End #mobile-menu-toggle -->
    <header>
        <div id="mobile-menu-close">
            <span>Close</span> <i class="fa fa-times" aria-hidden="true"></i>
        </div>
        <ul id="menu" class="shadow">
            <li>
                <a href="#about">About</a>
            </li>
            <li>
                <a href="#experience">Experience</a>
            </li>
            <li>
                <a href="#education">Education</a>
            </li>
            <li>
                <a href="#projects">Publications</a>
            </li>
            <li>
                <a href="#skills">Skills</a>
            </li>
            <li>
                <a href="#contact">Contact</a>
            </li>
        </ul>
    </header>
    <!-- End header -->

    <div id="lead">
        <div id="lead-content">
            <h1>Mohsen Fayyaz</h1>
            <h2>PhD Candidate, University of Bonn, Computer Vision Group of <a href="http://pages.iai.uni-bonn.de/gall_juergen/" target="_blank" style="color: LightCyan">Prof. Dr. Juergen Gall</a></h2>
            <a href="https://www.linkedin.com/in/mfayaz/" class="btn-rounded-white">See My Resume</a>
        </div>
        <!-- End #lead-content -->

        <div id="lead-overlay"></div>

        <div id="lead-down">
            <span>
                <i class="fa fa-chevron-down" aria-hidden="true"></i>
            </span>
        </div>
        <!-- End #lead-down -->
    </div>
    <!-- End #lead -->

    <div id="about">
        <div class="container">
            <div class="row">
                <div class="col-md-4">
                    <h2 class="heading">About Me</h2>
                </div>
                <div class="col-md-8">
                    <p>
                        Experienced Doctoral Researcher at the university of Bonn with a demonstrated history of working in the research industry. Skilled in Computer Vision and Deep Learning. Strong research professional with a Master’s Degree focused in Artificial Intelligence from MUT.
                    </p>
                </div>
            </div>
        </div>
    </div>
    <!-- End #about -->

    <div id="experience" class="background-alt">
        <h2 class="heading">Experience</h2>
        <div id="experience-timeline">
            <div data-date="November 2017 – Now">
                <h3>University of Bonn</h3>
                <h4>Doctoral Researcher</h4>
                <p>
                    Computer vision doctoral researcher at the University of Bonn, faculty of Computer Science III under supervision of <a href="http://pages.iai.uni-bonn.de/gall_juergen/" target="_blank">Prof. Dr. J. Gall</a>.
                </p>
            </div>

            <div data-date="April 2016 – October 2017">
                <h3>Sensifai</h3>
                <h4>Deep Learning Researcher</h4>
                <p>
			Designing and Developing Deep Neural Networks Architectures for Computer Vision Tasks. 
                </p>
            </div>

            <div data-date="September 2014 – August 2016">
                <h3>Iran University of Science and Technology</h3>
                <h4>Graduate Student Researcher</h4>
                <p>
                    Machine learning and Deep learning researcher in IUST HPC lab with the supervision of Prof. Dr. M. Fathy.
                </p>
            </div>
        </div>
    </div>
    <!-- End #experience -->

    <div id="education">
        <h2 class="heading">Education</h2>
        <div class="education-block">
            <h3><a href="http://www.uni-bonn.de" target="_blank">University of Bonn</a></h3>
            <span class="education-date">November 2017 - Now</span>
            <h4>PhD Candidate, Computer Science</h4>
            <p>
                Supervisor: <a href="http://pages.iai.uni-bonn.de/gall_juergen/" target="_blank">Prof. Dr. J. Gall</a>
            </p>
        </div>
        <!-- End .education-block -->

	<div class="education-block">
            <h3>MUT</h3>
            <span class="education-date">September 2014 - September 2016</span>
            <h4>Master of Science in Computer Engineering - Artificial Intelligence</h4>
            <p>
                Supervisors: Prof. Mahmood Fathy, Dr. Mojtaba Hosseini<br>
		Advisor: Dr. Mohammad Sabokrou<br>
		Thesis: Activity Recognition in Video based on Convolutional Neural Networks<br>
		GPA: 4.00/4.00<br>
		Ranked First with highest GPA among all Computer Engineering students (AI) since 2014
            </p>
        </div>
        <!-- End .education-block -->

        <div class="education-block">
            <h3>Semnan University</h3>
            <span class="education-date">September 2010 - September 2014</span>
            <h4>Bachelor of Science in Computer Software Engineering</h4>
            <p>
              	Supervisor: Dr. K. Kiani<br>
		Thesis: Designing and Implementing a Cloud-based Accounting System<br>
		Ranked First with highest GPA among all of the university computer engineering students since 2010  
            </p>
        </div>
        <!-- End .education-block -->
    </div>
    <!-- End #education -->

    <div id="projects" class="background-alt">
        <h2 class="heading">Publications</h2>
        <div class="container">
            <div class="row">
		    <div class="project shadow-large">
                    <div class="project-image">
                        <img src="images/Papers/ACCV18.png" width=300 height=300 />
                    </div>
                    <!-- End .project-image -->
                    <div class="project-info">
                        <h3>AVID: Adversarial Visual Irregularity Detection</h3>
                        <p>
                            <b>2018 - ACCV</b><br>
			    <b>M. Sabokrou<sup>*</sup>, M. Pourreza<sup>*</sup>, M. Fayyaz<sup>*</sup>, R. Entezari, R. Fathy, J. Gall, E. Adeli</b><br>
Real-time detection of irregularities in visual data is very invaluable and useful in many prospective applications including surveillance, patient monitoring systems, etc. With the surge of deep learning methods in the recent years, researchers have tried a wide spectrum of methods for different applications. However, for the case of irregularity or anomaly detection in videos, training an end-to-end model is still an open challenge, since often irregularity is not well-defined and there are not enough irregular samples to use during training ...
                        </p>
                        <a href="https://arxiv.org/pdf/1805.09521.pdf">See Publication</a>
                    </div>
                    <!-- End .project-info -->
                </div>
                <!-- End .project -->
		    <div class="project shadow-large">
                    <div class="project-image">
                        <img src="images/Papers/ECCV18.png" width=300 height=300 />
                    </div>
                    <!-- End .project-image -->
                    <div class="project-info">
                        <h3>Spatio-Temporal Channel Correlation Networks for Action Classification</h3>
                        <p>
                            <b>July 2018 - ECCV</b><br>
			    <b>A. Diba<sup>*</sup>, M. Fayyaz<sup>*</sup>, V. Sharma, M. Arzani, R. Yousefzadeh, J. Gall, L. Van Gool</b><br>
The work in this paper is driven by the question if spatio-temporal correlations are enough 
for 3D convolutional neural networks (CNN)? Most of the traditional 3D networks use local 
spatio-temporal features. We introduce a new block that models correlations between 
channels of a 3D CNN with respect to temporal and spatial features. This new block can be 
added as a residual unit to different parts of 3D CNNs. We name our novel block'Spatio-
Temporal Channel Correlation'(STC)…
                        </p>
                        <a href="http://openaccess.thecvf.com/content_ECCV_2018/papers/Ali_Diba_Spatio-Temporal_Channel_Correlation_ECCV_2018_paper.pdf">See Publication</a>
                    </div>
                    <!-- End .project-info -->
                </div>
                <!-- End .project -->
		<div class="project shadow-large">
                    <div class="project-image">
                        <img src="images/project.jpg" />
                    </div>
                    <!-- End .project-image -->
                    <div class="project-info">
                        <h3>Temporal 3D ConvNets by Temporal Transition Layer</h3>
                        <p>
                            <b>May 2018 - CVPR Workshop on Brave New Ideas in Video Understanding 2018</b><br>
			    <b>A. Diba<sup>*</sup>, M. Fayyaz<sup>*</sup>, V. Sharma, A. Karami, M. Arzani, R. Yousefzadeh, L. Van Gool</b><br>
The work in this paper is driven by the question how to exploit the temporal cues available in videos for their accurate classification, and for human action recognition in particular? Thus far, the vision community has focused on spatio-temporal approaches with fixed temporal convolution kernel depths. We introduce a new temporal layer that models variable temporal convolution kernel depths. We embed this new temporal layer in our proposed 3D CNN. We extend the DenseNet architecture - which normally is 2D - with 3D filters and pooling kernels. We name our proposed video convolutional network `Temporal 3D ConvNet'~(T3D) and its new temporal layer `Temporal Transition Layer'~(TTL)...
                        </p>
                        <a href="http://openaccess.thecvf.com/CVPR2018_workshops/content_CVPR_2018/papers/w19/Diba_Temporal_3D_ConvNets_CVPR_2018_paper.pdf">See Publication</a>
                    </div>
                    <!-- End .project-info -->
                </div>
                <!-- End .project -->

		<div class="project shadow-large">
                    <div class="project-image">
                        <img src="images/project.jpg" />
                    </div>
                    <!-- End .project-image -->
                    <div class="project-info">
                        <h3>Deep-anomaly: Fully convolutional neural network for fast anomaly detection in crowded scenes</h3>
                        <p>
                            <b>March 2018 - Computer Vision and Image Understanding</b><br>
			    <b>M. Sabokro<sup>*</sup>, M. Fayyaz<sup>*</sup>, M. Fathy, Z. Moayed, R. Klette</b><br>
The detection of abnormal behaviour in crowded scenes has to deal with many challenges. This paper presents an efficient method for detection and localization of anomalies in videos. Using fully convolutional neural networks (FCNs) and temporal data, a pre-trained supervised FCN is transferred into an unsupervised FCN ensuring the detection of (global) anomalies in scenes. High performance in terms of speed and accuracy is achieved by investigating the cascaded detection as a result of reducing computation complexities...
                        </p>
                        <a href="https://www.sciencedirect.com/science/article/pii/S1077314218300249?via%3Dihub#!">See Publication</a>
                    </div>
                    <!-- End .project-info -->
                </div>
                <!-- End .project -->

                <div class="project shadow-large">
                    <div class="project-image">
                        <img src="images/project.jpg" />
                    </div>
                    <!-- End .project-image -->
                    <div class="project-info">
                        <h3>Deep-cascade: Cascading 3D Deep Neural Networks for Fast Anomaly Detection and Localization in Crowded Scenes</h3>
                        <p>
                            <b>Feb 2017 - IEEE Transactions on Image Processing</b><br>
			    <b>M. Sabokro, M. Fayyaz, M. Fathy, R. Klette</b><br>
This paper proposes a fast and reliable method for anomaly detection and localization in video data showing crowded scenes. Time-efficient anomaly localization is an ongoing challenge and subject of this paper. We propose a cubic patch-based method, characterized by a cascade of classifiers, which makes use of an advanced feature learning approach. Our cascade of classifiers has two main stages...
                        </p>
                        <a href="http://ieeexplore.ieee.org/abstract/document/7858798/?lipi=urn%3Ali%3Apage%3Ad_flagship3_profile_view_base%3Bto8V7%2FaVTHinS9Xj9MkMgw%3D%3D">See Publication</a>
                    </div>
                    <!-- End .project-info -->
                </div>
                <!-- End .project -->

		<div class="project shadow-large">
                    <div class="project-image">
                        <img src="images/project.jpg" />
                    </div>
                    <!-- End .project-image -->
                    <div class="project-info">
                        <h3>STFCN - Spatio-Temporal Fully Convolutional Neural Network for Semantic Segmentation of Street Scenes</h3>
                        <p>
                            <b>Sep 2016 - ACCV Workshop</b><br>
			    <b>M. Fayyaz, M. Sabokro, M. Hajizadeh, M. Fathy, F. Huang, R. Klette</b><br>
This paper presents a novel method to involve both spatial and temporal features for semantic video segmentation. Current work on convolutional neural networks(CNNs) has shown that CNNs provide advanced spatial features supporting a very good performance of solutions for both image and video analysis, especially for the semantic segmentation task.
			</p>
                        <a href="https://link.springer.com/chapter/10.1007/978-3-319-54407-6_33?lipi=urn%3Ali%3Apage%3Ad_flagship3_profile_view_base%3Bto8V7%2FaVTHinS9Xj9MkMgw%3D%3D">See Publication</a>
                    </div>
                    <!-- End .project-info -->
                </div>
                <!-- End .project -->
                
		<div class="project shadow-large">
                    <div class="project-image">
                        <img src="images/project.jpg" />
                    </div>
                    <!-- End .project-image -->
                    <div class="project-info">
                        <h3>A novel approach for Finger Vein verification based on self-taught learning</h3>
                        <p>
                            <b>Nov 2015 - 9th Iranian Conference on Machine Vision and Image Processing (MVIP)</b><br>
In this paper, we propose a method for user Finger Vein Authentication (FVA) as a biometric system. Using the discriminative features for classifying theses finger veins is one of the main tips that make difference in related works, thus we propose to learn a set of representative features, based on auto-encoders. 
			</p>
                        <a href="https://link.springer.com/chapter/10.1007/978-3-319-54407-6_33?lipi=urn%3Ali%3Apage%3Ad_flagship3_profile_view_base%3Bto8V7%2FaVTHinS9Xj9MkMgw%3D%3D">See Publication</a>
                    </div>
                    <!-- End .project-info -->
                </div>
                <!-- End .project -->

    <div id="skills">
        <h2 class="heading">Skills</h2>
        <ul>
            <li>PyTorch</li>
	    <li>Torch</li>
	    <li>Tensorflow</li>
	    <li>Caffe</li>
            <li>Python</li>
            <li>C</li>
            <li>C#</li>
            <li>C++</li>
        </ul>
    </div>
    <!-- End #skills -->

    <div id="contact">
        <h2>Get in Touch</h2>
        <div id="contact-form">
            <form method="POST" action="https://formspree.io/mohsen.fayyaz89@gmail.com">
                <input type="hidden" name="_subject" value="Contact request from personal website" />
                <input type="email" name="_replyto" placeholder="Your email" required>
                <textarea name="message" placeholder="Your message" required></textarea>
                <button type="submit">Send</button>
            </form>
        </div>
        <!-- End #contact-form -->
    </div>
    <!-- End #contact -->

    <footer>
        <div class="container">
            <div class="row">
                <div class="col-sm-5 copyright">
                    <p>
                        
                    </p>
                </div>
                <div class="col-sm-2 top">
                    <span id="to-top">
                        <i class="fa fa-chevron-up" aria-hidden="true"></i>
                    </span>
                </div>
                <div class="col-sm-5 social">
                    <ul>
                        <li>
                            <a href="https://mohsenfayyaz89.github.com/" target="_blank"><i class="fa fa-github" aria-hidden="true"></i></a>
                        </li>
                        <li>
                            <a href="https://stackoverflow.com/" target="_blank"><i class="fa fa-stack-overflow" aria-hidden="true"></i></a>
                        </li>
                        <li>
                            <a href="https://www.facebook.com/mohsen.fayyaz" target="_blank"><i class="fa fa-facebook" aria-hidden="true"></i></a>
                        </li>
                        <li>
                            <a href="https://twitter.com/MohsenFyz" target="_blank"><i class="fa fa-twitter" aria-hidden="true"></i></a>
                        </li>
                        <li>
                            <a href="https://plus.google.com/" target="_blank"><i class="fa fa-google-plus" aria-hidden="true"></i></a>
                        </li>
                    </ul>
                </div>
            </div>
        </div>
    </footer>
    <!-- End footer -->

    <script src="https://ajax.googleapis.com/ajax/libs/jquery/1.12.4/jquery.min.js"></script>
    <script src="js/scripts.min.js"></script>
</body>

</html>
